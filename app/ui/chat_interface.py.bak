import os
from typing import List, Dict, Any, Callable, Optional, Union, AsyncGenerator
import gradio as gr
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, BaseMessage
from langchain_core.memory import BaseMemory
from langchain.chains import ConversationalRetrievalChain
from langchain.schema import Document
from sqlalchemy import select, func
from sqlalchemy.sql import text
from dotenv import load_dotenv
from langchain_core.retrievers import BaseRetriever
from langchain_core.callbacks.manager import CallbackManagerForRetrieverRun
from pydantic import BaseModel, Field
from langchain_core.runnables import RunnableConfig
from langchain_core.messages import trim_messages
from langchain.prompts import PromptTemplate, ChatPromptTemplate
from langchain.prompts.prompt import PromptTemplate
import tiktoken
import asyncio
import re
from app.config import prompt_config
from pgvector.sqlalchemy import Vector
import numpy as np
import shutil
from pathlib import Path
import logging
import plotly.graph_objects as go
from pyvis.network import Network
import json
import tempfile
import random
from utils.vector_store_visualization import (
    VectorStoreDataAcquisition,
    VectorStoreVisualization,
    visualize_vector_store
)
from sqlalchemy.ext.asyncio import AsyncSession
import hashlib
from datetime import datetime

from app.config import chat_config, db_config, processor_config, PostgresConfig, ProcessorConfig

from app.core.document_rag_loader import (
    DocumentModel,
    DocumentChunk,
    PostgresConfig,
    async_sessionmaker,
    create_async_engine,
    OpenAIEmbeddings,
    DocumentProcessor,
    ProcessorConfig,
    calculate_file_checksum,
    check_duplicate_document,
    sanitize_text
)

# Load environment variables
load_dotenv()
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PostgresVectorRetriever(BaseRetriever, BaseModel):
    """Custom retriever for PostgreSQL vector store"""
    
    session_maker: Callable = Field(..., description="Async session maker for PostgreSQL")
    embeddings: Any = Field(..., description="Embeddings model")
    k: int = Field(default=chat_config.retriever_k, description="Number of documents to retrieve")
    score_threshold: float = Field(default=chat_config.retriever_score_threshold, description="Minimum similarity score threshold")
    
    class Config:
        arbitrary_types_allowed = True
    
    async def _aget_relevant_documents(self, query: str) -> List[Document]:
        """Get relevant documents for a query using vector similarity search."""
        try:
            # Generate embedding for query
            query_embedding = await self.embeddings.aembed_query(query)
            if isinstance(query_embedding, np.ndarray):
                query_embedding = query_embedding.astype(np.float32).tolist()
            
            # Convert embedding to PostgreSQL vector string format
            query_embedding_str = f"[{','.join(map(str, query_embedding))}]"
            
            print(f"‚úì Generated embedding for query: {query[:50]}...")
            
            async with self.session_maker() as session:
                # Ensure pgvector extension is installed
                await session.execute(text("CREATE EXTENSION IF NOT EXISTS vector;"))
                
                # SQL query for similarity search using cosine distance
                sql = text("""
                    WITH similarity_scores AS (
                        SELECT 
                            dc.content,
                            dc.chunk_index,
                            dc.chunk_size,
                            dc.page_number,
                            dm.filename,
                            dc.chunk_metadata,
                            1 - (dc.embedding <=> CAST(:embedding AS vector)) as similarity_score
                        FROM document_chunks dc
                        JOIN documents dm ON dc.document_id = dm.id
                        WHERE 1 - (dc.embedding <=> CAST(:embedding AS vector)) > :threshold
                        ORDER BY similarity_score DESC
                        LIMIT :limit
                    )
                    SELECT * FROM similarity_scores;
                """)
                
                # Execute search with parameters
                result = await session.execute(
                    sql,
                    {
                        "embedding": query_embedding_str,
                        "threshold": self.score_threshold,
                        "limit": self.k
                    }
                )
                
                # Process results into Documents
                documents = []
                for row in result:
                    doc = Document(
                        page_content=row.content,
                        metadata={
                            'source': row.filename,
                            'page': row.page_number,
                            'chunk_index': row.chunk_index,
                            'chunk_size': row.chunk_size,
                            'similarity_score': row.similarity_score,
                            **(row.chunk_metadata or {})
                        }
                    )
                    documents.append(doc)
                
                print(f"‚úì Found {len(documents)} matching documents")
                return documents
                
        except Exception as e:
            print("\n=== Document Retrieval Error ===")
            print(f"Error type: {type(e).__name__}")
            print(f"Error message: {str(e)}")
            print("Traceback:")
            import traceback
            print(traceback.format_exc())
            return []
    
    def _get_relevant_documents(
        self, 
        query: str,
        *,
        runnable_manager: Optional[CallbackManagerForRetrieverRun] = None
    ) -> List[Document]:
        """Synchronous method to get relevant documents"""
        raise NotImplementedError("This retriever only supports async operations")

class ChatInterface:
    """Handles chat interface and conversation"""
    
    def __init__(self):
        self.documents_dir = Path(chat_config.documents_dir)
        self.documents_dir.mkdir(exist_ok=True)
        
        # Create PostgreSQL connection string
        self.postgres_config = PostgresConfig(
            connection_string=db_config.connection_string,
            pre_delete_collection=False,
            drop_existing=False
        )
        
        # Create async engine and session
        self.engine = create_async_engine(
            self.postgres_config.connection_string,
            echo=False,
            pool_size=5,
            max_overflow=10
        )
        self.async_session = async_sessionmaker(self.engine, expire_on_commit=False)
        
        # Initialize embeddings
        self.embeddings = OpenAIEmbeddings(
            openai_api_key=OPENAI_API_KEY,
            model="text-embedding-ada-002"
        )
        
        # Initialize retriever
        self.retriever = PostgresVectorRetriever(
            session_maker=self.async_session,
            embeddings=self.embeddings,
            k=chat_config.retriever_k,
            score_threshold=chat_config.retriever_score_threshold
        )
        
        # Initialize LLM
        self.llm = ChatOpenAI(
            model=chat_config.model,
            temperature=chat_config.temperature,
            max_tokens=chat_config.max_tokens,
            streaming=chat_config.streaming
        )
        
        # Initialize chain
        self.chain = ConversationalRetrievalChain.from_llm(
            llm=self.llm,
            retriever=self.retriever,
            return_source_documents=True
        )
        
        # Initialize system message
        self.system_message = SystemMessage(
            content="You are a helpful assistant that answers questions based on the provided documents."
        )
        
        # Define prompt templates
        document_prompt = PromptTemplate(
            input_variables=["page_content"],
            template=prompt_config.document_template
        )

        qa_prompt = ChatPromptTemplate.from_template(prompt_config.qa_template)

        # Initialize conversation chain with correct parameters and prompts
        self.conversation_chain = ConversationalRetrievalChain.from_llm(
            llm=self.llm,
            retriever=self.retriever,
            verbose=True,
            return_source_documents=True,
            chain_type="stuff",
            combine_docs_chain_kwargs={
                "document_prompt": document_prompt,
                "document_variable_name": "context",
                "prompt": qa_prompt
            }
        )
        
        # Initialize conversation history
        self.messages = [self.system_message]
        
        # Initialize tokenizer and set max tokens
        self.tokenizer = tiktoken.encoding_for_model("gpt-3.5-turbo")
        self.max_token_limit = 4000  # Adjust based on your needs
        
        # Add debug logging
        self.debug = True
        
        # Test database connection at initialization
        if self.debug:
            asyncio.create_task(self.test_db_connection())
    
    def _count_tokens(self, messages: list) -> int:
        """Count tokens in concatenated message content"""
        try:
            text_content = " ".join([
                str(msg.content) 
                for msg in messages 
                if hasattr(msg, 'content') and msg.content is not None
            ])
            return len(self.tokenizer.encode(text_content))
        except Exception as e:
            print(f"Token counting error: {str(e)}")
            return 0
    
    def _trim_history(self):
        """Trim conversation history using LangChain's utilities"""
        try:
            # Validate messages
            validated_messages = [
                msg for msg in self.messages 
                if isinstance(msg, BaseMessage) and hasattr(msg, 'content')
            ]
            
            # Trim messages
            self.messages = trim_messages(
                messages=validated_messages,
                max_tokens=self.max_token_limit,
                token_counter=self._count_tokens,
                strategy="last"  # Keep most recent messages
            )
        except Exception as e:
            print(f"History trimming error: {str(e)}")
            # Keep only system message and last few messages if trimming fails
            self.messages = [self.system_message] + self.messages[-4:]
    
    async def chat(self, message: str, history: List[Dict[str, str]]) -> Dict[str, str]:
        """Process chat message and return response"""
        try:
            if self.debug:
                print(f"\nQuestion: {message}")
                print(f"History: {history}")
            
            # Convert history to messages format
            if not history:
                self.messages = [self.system_message]
            
            # Add user message
            user_message = HumanMessage(content=message)
            self.messages.append(user_message)
            
            # Trim history if needed
            self._trim_history()
            
            # Format chat history as tuples
            chat_history = []
            messages = self.messages[1:]  # Skip system message
            for i in range(0, len(messages)-1, 2):
                if i+1 < len(messages):
                    human_msg = messages[i]
                    ai_msg = messages[i+1]
                    if isinstance(human_msg, HumanMessage) and isinstance(ai_msg, AIMessage):
                        chat_history.append((human_msg.content, ai_msg.content))
            
            # Invoke chain
            result = await self.conversation_chain.ainvoke({
                "question": message,
                "chat_history": chat_history
            })
            
            # Create assistant message
            assistant_message = AIMessage(content=result["answer"])
            self.messages.append(assistant_message)
            
            # Format response with sources
            response = result["answer"]
            if "source_documents" in result and result["source_documents"]:
                unique_sources = {
                    doc.metadata['source']: doc.metadata.get('page', 'N/A') 
                    for doc in result["source_documents"]
                }
                sources = [
                    f"Source: {source} (Page: {page})" 
                    for source, page in unique_sources.items()
                ]
                response = f"{response}\n\nSources:\n" + "\n".join(sources)
            
            # Add debug logging for retrieved documents
            if self.debug and "source_documents" in result:
                print("\nRetrieved Documents:")
                for doc in result["source_documents"]:
                    print(f"Source: {doc.metadata['source']}")
                    print(f"Content: {doc.page_content[:200]}...")
            
            # Return in OpenAI message format
            return {"role": "assistant", "content": response}
            
        except Exception as e:
            import traceback
            print(f"Error: {str(e)}")
            print(traceback.format_exc())
            return {"role": "assistant", "content": f"Error processing question: {str(e)}"}
    
    async def cleanup(self):
        """Cleanup resources properly"""
        try:
            # Close any active sessions
            if hasattr(self, 'async_session'):
                async with self.async_session() as session:
                    await session.close()
            
            # Dispose of the engine
            if hasattr(self, 'engine'):
                await self.engine.dispose()
            
        except Exception as e:
            logger.error(f"Error during cleanup: {str(e)}")

    async def test_db_connection(self):
        """Test database connection and document retrieval"""
        try:
            async with self.async_session() as session:
                # Try to get one document
                result = await session.execute(
                    select(DocumentModel).limit(1)
                )
                doc = result.scalar_one_or_none()
                if doc:
                    print("\n=== üîç Database Connection Test ===")
                    print("‚úÖ Successfully connected to database")
                    print(f"üìÑ Found document: {doc.filename}")
                    
                    # Test vector retrieval
                    test_query = "test query"
                    docs = await self.retriever._aget_relevant_documents(
                        test_query
                    )
                    print(f"‚úÖ Vector retrieval test: found {len(docs)} documents")
                    return True
                else:
                    print("‚ö†Ô∏è No documents found in database")
                    return False
        except Exception as e:
            print("\n=== ‚ùå Database Connection Error ===")
            print(f"Error type: {type(e).__name__}")
            print(f"Error message: {str(e)}")
            import traceback
            print("Traceback:")
            print(traceback.format_exc())
            return False

    async def handle_file_upload(self, files: List[str]) -> str:
        """Handle initial file upload to temporary storage"""
        try:
            logger.info(f"\nüì§ Received {len(files)} files")
            
            html_output = ["<div>"]
            html_output.append(f"<b>üì§ Received {len(files)} files</b><br>")
            
            successful_uploads = []
            for file_path in files:
                try:
                    # Convert to Path object
                    source_path = Path(file_path)
                    
                    # Create destination path in documents directory
                    dest_path = self.documents_dir / source_path.name
                    
                    # Handle duplicate filenames
                    counter = 1
                    while dest_path.exists():
                        stem = source_path.stem
                        suffix = source_path.suffix
                        new_name = f"{stem}_{counter}{suffix}"
                        dest_path = self.documents_dir / new_name
                        counter += 1
                    
                    logger.info(f"Moving {source_path} to {dest_path}")
                    
                    # Move file to documents directory
                    shutil.move(str(source_path), str(dest_path))
                    
                    successful_uploads.append(dest_path.name)
                    html_output.append(f"‚úÖ Successfully moved <span style='color: green;'>{dest_path.name}</span><br>")
                    logger.info(f"‚úÖ Successfully moved {dest_path.name}")
                    
                except Exception as e:
                    html_output.append(f"‚ùå Error processing <span style='color: red;'>{file_path}</span>: {str(e)}<br>")
                    logger.error(f"‚ùå Error processing {file_path}: {str(e)}")
                    continue

            if successful_uploads:
                html_output.append("<br><b>Successfully uploaded files:</b><br>")
                for f in successful_uploads:
                    html_output.append(f"- <span style='color: green;'>{f}</span><br>")
                html_output.append("<br><b>Click 'Process Documents' to proceed with document processing.</b>")
            else:
                html_output.append("<br><span style='color: red;'>No files were successfully uploaded</span>")
            
            html_output.append("</div>")
            return "".join(html_output)
            
        except Exception as e:
            logger.error(f"‚ùå Upload error: {str(e)}", exc_info=True)
            return f"<div style='color: red;'>Error uploading files: {str(e)}</div>"

    def calculate_file_checksum(self, file_path: str) -> str:
        """
        Calculate SHA-256 checksum for a file
        
        Args:
            file_path: Path to the file
            
        Returns:
            Hexadecimal digest of the SHA-256 hash
        """
        try:
            sha256_hash = hashlib.sha256()
            with open(file_path, "rb") as f:
                # Read the file in chunks to handle large files efficiently
                for byte_block in iter(lambda: f.read(4096), b""):
                    sha256_hash.update(byte_block)
            return sha256_hash.hexdigest()
        except Exception as e:
            print(f"Error calculating checksum for {file_path}: {e}")
            return None

    async def process_single_file(self, file_path: Path, processor_config: ProcessorConfig) -> Optional[List[Document]]:
        """Process a single file with document processor."""
        try:
            print(f"\n=== Processing File: {file_path.name} ===")
            print(f"Checksum: {self.calculate_file_checksum(str(file_path))}")
            
            # Initialize processor for embeddings
            processor = DocumentProcessor(processor_config)
            
            # Load and process the document to get chunks and embeddings
            documents = await processor._load_document(str(file_path))
            if not documents:
                print(f"‚ö†Ô∏è No content extracted from {file_path.name}")
                return None
            
            # Process in batches like document_rag_loader
            all_chunks = []
            
            # Calculate checksum once for the file
            checksum = self.calculate_file_checksum(str(file_path))
            
            # Check for duplicate file first
            async with self.async_session() as session:
                result = await session.execute(
                    select(DocumentModel).where(DocumentModel.checksum == checksum)
                )
                if result.scalar_one_or_none():
                    print(f"‚è© Document {file_path.name} already exists with same checksum")
                    return None
            
            # Process document in batches
            for i in range(0, len(documents), processor_config.batch_size):
                batch = documents[i:i + processor_config.batch_size]
                
                # Get text content
                texts = [doc.page_content for doc in batch]
                
                # Get embeddings
                embeddings = await processor._get_embeddings_batch(texts)
                
                # Validate chunks before database operations
                valid_chunks = []
                valid_embeddings = []
                
                for idx, (chunk, embedding) in enumerate(zip(batch, embeddings)):
                    content = sanitize_text(chunk.page_content)
                    if not content:
                        print(f"Skipping chunk {idx}: Empty or invalid content")
                        continue
                    
                    chunk.page_content = content
                    valid_chunks.append(chunk)
                    valid_embeddings.append(embedding)
                
                if not valid_chunks:
                    print(f"No valid chunks found in batch")
                    continue
                
                # Process database operations in a single transaction
                async with self.async_session() as session:
                    try:
                        async with session.begin():
                            # Final duplicate check before insert
                            result = await session.execute(
                                select(DocumentModel).where(DocumentModel.checksum == checksum)
                            )
                            if result.scalar_one_or_none():
                                print(f"‚ö†Ô∏è Race condition detected! Document was inserted by another process")
                                return None
                            
                            # Create document record if this is the first batch
                            if not all_chunks:  # Only create document on first batch
                                doc = DocumentModel(
                                    filename=file_path.name,
                                    checksum=checksum,
                                    doc_metadata={
                                        'source': file_path.name,
                                        'file_path': str(file_path),
                                        'processed_at': datetime.now().isoformat()
                                    }
                                )
                                session.add(doc)
                                await session.flush()
                                doc_id = doc.id
                            
                            # Create chunk records
                            for idx, (chunk, embedding) in enumerate(zip(valid_chunks, valid_embeddings)):
                                chunk_record = DocumentChunk(
                                    document_id=doc_id,
                                    content=chunk.page_content,
                                    embedding=embedding,
                                    chunk_index=len(all_chunks) + idx,  # Global index across all batches
                                    chunk_size=len(chunk.page_content),
                                    page_number=chunk.metadata.get('page', None),
                                    section_title=chunk.metadata.get('section_title', None),
                                    chunk_metadata={
                                        **chunk.metadata,
                                        'processed_at': datetime.now().isoformat(),
                                        'embedding_model': 'text-embedding-ada-002',
                                        'batch_index': i // processor_config.batch_size
                                    }
                                )
                                session.add(chunk_record)
                        
                        print(f"‚úÖ Stored batch with {len(valid_chunks)} chunks")
                        all_chunks.extend(valid_chunks)
                        
                    except Exception as e:
                        print(f"‚ùå Transaction error: {str(e)}")
                        raise
            
            if all_chunks:
                print(f"‚úÖ Successfully processed {file_path.name} with {len(all_chunks)} total chunks")
            return all_chunks

        except Exception as e:
            print(f"‚ùå Error processing file {file_path}: {str(e)}")
            logger.error(f"Error processing {file_path}: {str(e)}", exc_info=True)
            raise

    async def process_documents(self, loader_type="Docling (Enhanced)") -> str:
        """Process the uploaded documents with progress tracking"""
        try:
            logger.info("Starting document processing...")
            print("\n=== Document Processing Started ===")
            
            # Initialize database tables if needed
            async with self.async_session() as session:
                # Create extensions if they don't exist
                await session.execute(text("CREATE EXTENSION IF NOT EXISTS vector;"))
                await session.execute(text("CREATE EXTENSION IF NOT EXISTS pgcrypto;"))
                await session.commit()
                
                # Create index if it doesn't exist
                try:
                    await session.execute(
                        text("CREATE UNIQUE INDEX IF NOT EXISTS idx_documents_checksum ON documents (checksum);")
                    )
                    await session.commit()
                    logger.info("Tables and indices created successfully")
                except Exception as e:
                    logger.warning(f"Index creation warning (can be ignored if already exists): {str(e)}")
            
            # Get all files in documents directory
            all_files = list(self.documents_dir.glob('*.*'))
            total_files = len(all_files)
            print(f"Found {total_files} files to process")
            
            # Process files with checksum verification
            total_chunks = 0
            processed_files = []
            skipped_files = []
            error_files = []
            
            # First, get all existing checksums in a separate session
            existing_checksums = {}
            existing_filenames = {}
            
            async with self.async_session() as session:
                result = await session.execute(select(DocumentModel))
                existing_docs = result.scalars().all()
                
                for doc in existing_docs:
                    existing_checksums[doc.checksum] = doc.id
                    existing_filenames[doc.filename] = doc.checksum
            
            print(f"\n=== Existing Documents in Database ===")
            print(f"Found {len(existing_checksums)} documents in database")
            print("All checksums in database:")
            for checksum, doc_id in existing_checksums.items():
                print(f"ID: {doc_id} | Checksum: {checksum[:8]}...")
            
            # Create processor config
            postgres_config = PostgresConfig(
                connection_string=self.postgres_config.connection_string,
                pre_delete_collection=False,
                drop_existing=False
            )
            
            # Determine which loader to use based on selection
            use_docling = False
            use_mistral = False
            loader_name = "LangChain"
            
            if loader_type == "Docling (Enhanced)":
                use_docling = True
                loader_name = "Docling (Enhanced)"
            elif loader_type == "Mistral OCR":
                use_mistral = True
                loader_name = "Mistral OCR"
                
            # Log the selected loader
            logger.info(f"Using document loader: {loader_name}")
            print(f"\n=== üìö Document Loader: {loader_name} ===\n")
                
            processor_config = ProcessorConfig(
                chunk_size=500,
                chunk_overlap=50,
                vector_store_type="postgres",
                postgres_config=postgres_config,
                batch_size=50,
                max_workers=1,
                db_pool_size=5,
                openai_api_key=OPENAI_API_KEY,
                # Set loader options based on user selection
                use_docling=use_docling,
                docling_artifacts_path=os.getenv('DOCLING_ARTIFACTS_PATH'),
                docling_enable_remote=os.getenv('DOCLING_ENABLE_REMOTE', '').lower() in ('true', '1', 'yes'),
                docling_use_cache=os.getenv('DOCLING_USE_CACHE', 'true').lower() in ('true', '1', 'yes'),
                use_mistral=use_mistral,
                mistral_api_key=os.getenv('MISTRAL_API_KEY'),
                mistral_ocr_model=os.getenv('MISTRAL_OCR_MODEL', 'mistral-ocr-latest'),
                mistral_include_images=os.getenv('MISTRAL_INCLUDE_IMAGES', '').lower() in ('true', '1', 'yes')
            )
            
            # Process each file
            for file_path in all_files:
                try:
                    # Calculate checksum
                    file_checksum = calculate_file_checksum(str(file_path))
                    print(f"\n===== Checking file: {file_path.name} =====")
                    print(f"Calculated checksum: {file_checksum}")
                    
                    # Check if file exists in database by checksum
                    checksum_exists = file_checksum in existing_checksums
                    print(f"Checksum exists in database? {checksum_exists}")
                    
                    if checksum_exists:
                        print(f"‚è© Skipping {file_path.name} - found matching checksum in database")
                        logger.info(f"Skipping {file_path.name} - already exists with checksum {file_checksum}")
                        skipped_files.append(file_path.name)
                        continue
                    
                    # Process file
                    print(f"üîÑ Processing {file_path.name}...")
                    logger.info(f"Processing {file_path.name}")
                    chunks = await self.process_single_file(file_path, processor_config)
                    
                    if chunks:
                        total_chunks += len(chunks)
                        processed_files.append(file_path.name)
                        print(f"‚úÖ Processed {file_path.name} - created {len(chunks)} chunks")
                        
                        # Update our local cache
                        existing_checksums[file_checksum] = True
                        existing_filenames[file_path.name] = file_checksum
                    
                except Exception as e:
                    print(f"‚ùå Error processing {file_path.name}: {str(e)}")
                    logger.error(f"Error processing {file_path.name}: {str(e)}")
                    error_files.append(file_path.name)
                    continue
            
            # Create status message with HTML formatting
            status_message = []
            status_message.append("<div style='padding: 10px; background-color: #1a1a1a; border-radius: 5px;'>")
            status_message.append("<h3 style='text-align: center; color: #ffffff;'>=== Processing Summary ===</h3>")
            status_message.append(f"<p><b>Total files:</b> {len(all_files)}</p>")
            
            if processed_files:
                status_message.append(f"<p><b>Successfully processed files:</b> {len(processed_files)}</p>")
                status_message.append("<ul>")
                for file in processed_files:
                    status_message.append(f"<li style='color: #00cc00;'>{file}</li>")
                status_message.append("</ul>")
                status_message.append(f"<p><b>Total chunks created:</b> {total_chunks}</p>")
            
            if skipped_files:
                status_message.append(f"<p><b>Skipped files:</b> {len(skipped_files)}</p>")
                status_message.append("<ul>")
                for file in skipped_files:
                    status_message.append(f"<li style='color: orange;'>{file}</li>")
                status_message.append("</ul>")
            
            if error_files:
                status_message.append(f"<p><b>Files with errors:</b> {len(error_files)}</p>")
                status_message.append("<ul>")
                for file in error_files:
                    status_message.append(f"<li style='color: #ff3333;'>{file}</li>")
                status_message.append("</ul>")
                status_message.append("<p>Check logs for detailed error information.</p>")
            
            status_message.append("</div>")
            return "".join(status_message)
            
        except Exception as e:
            error_message = f"<div style='color: red; padding: 10px;'>Error processing documents: {str(e)}</div>"
            logger.error(error_message, exc_info=True)
            return error_message

    async def stream_chat(self, message: str, history: List[Dict[str, str]]) -> AsyncGenerator[Dict[str, str], None]:
        """Process chat message and stream response"""
        try:
            # Add debug flag to track streaming
            streaming_debug = True
            
            if streaming_debug:
                print(f"\nüîÑ Starting streaming response for: {message}")
            
            if self.debug:
                print(f"\nüìù Question: {message}")
                print(f"üìö History length: {len(history) if history else 0}")
            
            # Convert history to messages format if needed
            if not self.messages or len(self.messages) <= 1:  # Only system message or empty
                self.messages = [self.system_message]
                
                # Convert history to messages if available
                if history:
                    for h_msg, a_msg in history:
                        self.messages.append(HumanMessage(content=h_msg))
                        self.messages.append(AIMessage(content=a_msg))
            
            # Add user message
            user_message = HumanMessage(content=message)
            self.messages.append(user_message)
            
            # Trim history if needed
            self._trim_history()
            
            # Format chat history as tuples for the prompt
            chat_history = []
            messages = self.messages[1:]  # Skip system message
            for i in range(0, len(messages)-1, 2):
                if i+1 < len(messages):
                    human_msg = messages[i]
                    ai_msg = messages[i+1]
                    if isinstance(human_msg, HumanMessage) and isinstance(ai_msg, AIMessage):
                        chat_history.append((human_msg.content, ai_msg.content))
            
            # Prepare for streaming - get relevant documents
            docs = await self.retriever._aget_relevant_documents(message)
            
            if self.debug:
                print("\nüìÑ Retrieved Documents:")
                for i, doc in enumerate(docs):
                    print(f"  üìë Doc {i+1}: {doc.metadata['source']} (Page: {doc.metadata.get('page', 'N/A')})")
                    print(f"  üìù Content: {doc.page_content[:100]}...")
            
            # Format documents for context
            context = "\n\n".join([doc.page_content for doc in docs])
            
            # Create a streaming LLM
            streaming_llm = ChatOpenAI(
                model=chat_config.model,
                temperature=chat_config.temperature,
                max_tokens=chat_config.max_tokens,
                streaming=True
            )
            
            # Create prompt template
            prompt = ChatPromptTemplate.from_template(prompt_config.qa_template)
            
            # Format chat history for prompt
            formatted_chat_history = ""
            for human, ai in chat_history:
                formatted_chat_history += f"Human: {human}\nAI: {ai}\n\n"
            
            # Create the chain
            chain = prompt | streaming_llm
            
            # Start streaming response
            full_response = ""
            
            # Invoke the chain with streaming
            async for chunk in chain.astream({
                "context": context,
                "chat_history": formatted_chat_history,
                "question": message
            }):
                if hasattr(chunk, 'content'):
                    content = chunk.content
                    full_response += content
                    
                    if streaming_debug and len(content) > 0:
                        print(f"üî§ Streaming chunk: {content[:20]}...")
                    
                    # Yield the current state of the response
                    yield {"role": "assistant", "content": full_response}
            
            if streaming_debug:
                print(f"‚úÖ Streaming complete, final length: {len(full_response)}")
            
            # After streaming is complete, add sources information
            if docs:
                unique_sources = {
                    doc.metadata['source']: doc.metadata.get('page', 'N/A') 
                    for doc in docs
                }
                sources = [
                    f"Source: {source} (Page: {page})" 
                    for source, page in unique_sources.items()
                ]
                final_response = f"{full_response}\n\nSources:\n" + "\n".join(sources)
                
                # Yield the final response with sources
                yield {"role": "assistant", "content": final_response}
                
                # Create assistant message for history
                assistant_message = AIMessage(content=final_response)
                self.messages.append(assistant_message)
            else:
                # Create assistant message for history
                assistant_message = AIMessage(content=full_response)
                self.messages.append(assistant_message)
                
                # Yield the final response
                yield {"role": "assistant", "content": full_response}
            
        except Exception as e:
            import traceback
            print(f"‚ùå Error: {str(e)}")
            print(traceback.format_exc())
            yield {"role": "assistant", "content": f"Error processing question: {str(e)}"}

    async def check_database_integrity(self):
        """Check database tables for data integrity"""
        try:
            async with self.async_session() as session:
                # Check documents table
                print("\n=== Checking Documents Table ===")
                result = await session.execute(select(DocumentModel))
                documents = result.scalars().all()
                print(f"Total documents: {len(documents)}")
                
                for doc in documents:
                    print(f"\nDocument ID: {doc.id}")
                    print(f"Filename: {doc.filename}")
                    print(f"Checksum: {doc.checksum}")
                    print(f"Metadata: {doc.doc_metadata}")
                    
                    # Check associated chunks
                    chunk_result = await session.execute(
                        select(DocumentChunk)
                        .where(DocumentChunk.document_id == doc.id)
                    )
                    chunks = chunk_result.scalars().all()
                    print(f"Number of chunks: {len(chunks)}")
                    
                    if chunks:
                        # Check first and last chunk
                        print("\nFirst chunk details:")
                        print(f"Content length: {len(chunks[0].content)}")
                        print(f"Embedding dimension: {len(chunks[0].embedding)}")
                        print(f"Metadata: {chunks[0].chunk_metadata}")
                        
                        print("\nLast chunk details:")
                        print(f"Content length: {len(chunks[-1].content)}")
                        print(f"Embedding dimension: {len(chunks[-1].embedding)}")
                        print(f"Metadata: {chunks[-1].chunk_metadata}")
                    
                # Check for orphaned chunks
                print("\n=== Checking for Orphaned Chunks ===")
                orphaned_result = await session.execute(
                    select(DocumentChunk)
                    .outerjoin(DocumentModel)
                    .where(DocumentModel.id == None)
                )
                orphaned_chunks = orphaned_result.scalars().all()
                if orphaned_chunks:
                    print(f"Warning: Found {len(orphaned_chunks)} orphaned chunks!")
                else:
                    print("No orphaned chunks found.")
                
                return True
                
        except Exception as e:
            print(f"Error checking database: {str(e)}")
            logger.error(f"Database check error: {str(e)}", exc_info=True)
            return False

async def main():
    """Main function to run the chat interface"""
    chat_interface = None
    try:
        chat_interface = ChatInterface()
        
        with gr.Blocks() as demo:
            gr.Markdown("""
                <div style="text-align: center; margin-bottom: 20px;">
                    <h1>Document Q&A System</h1>
                    <p>Ask questions about your documents. The system will search through the document collection and provide relevant answers.</p>
                </div>
            """)
            
            # Add global CSS for document accordion only
            gr.HTML("""
            <style>
            /* Target document accordion by ID and make everything inside it white */
            #document-accordion,
            #document-accordion > div,
            #document-accordion > div > div,
            #document-accordion > div > div > div,
            #document-accordion [class*="bg-gray"],
            #document-accordion [data-testid="accordion-content"],
            #document-accordion [data-testid="accordion-content"] > div {
                background-color: white !important;
            }
            
            /* Force white background on any potentially gray backgrounds */
            #document-accordion .bg-gray-50,
            #document-accordion .bg-gray-100,
            #document-accordion .bg-gray-200,
            #document-accordion .prose,
            #document-accordion .contain,
            #document-accordion .block {
                background-color: white !important;
            }
            
            /* Target document accordion with direct child selectors to be thorough */
            #document-accordion > * {
                background-color: white !important;
            }
            
            /* Special selector for the row containers */
            #document-accordion .gr-padded {
                background-color: white !important;
            }
            
            /* Overlay to force white background */
            #document-accordion::before {
                content: "";
                position: absolute;
                top: 0;
                left: 0;
                width: 100%;
                height: 100%;
                background-color: white;
                z-index: -1;
            }
            </style>
            """, visible=False)
            
            # Document Upload Accordion with white background
            with gr.Accordion("Document Upload/Processing", open=False, elem_id="document-accordion"):
                upload_button = gr.UploadButton(
                    "Click to Upload Files",
                    variant="huggingface",
                    size="sm",
                    file_types=[".pdf", ".txt", ".doc", ".docx"],
                    file_count="multiple"
                )
                
                # Custom CSS to make the radio buttons display horizontally and centrally
                # Also set the background color to white specifically for this accordion
                gr.HTML("""
                <style>
                /* Change background color of document upload accordion to white */
                .white-bg {
                    background-color: white !important;
                }
                
                /* Target the accordion content area specifically */
                .white-bg > .grow {
                    background-color: white !important;
                }
                
                /* Set all children elements to have white background too */
                .white-bg > div,
                .white-bg > div > div,
                .white-bg .gradio-box,
                .white-bg .contain,
                .white-bg .prose,
                .white-bg .gap,
                .white-bg .block,
                .white-bg .relative,
                .white-bg .border,
                .white-bg .border-gray-200 {
                    background-color: white !important;
                }
                
                /* Direct targeting of the content below the header */
                .white-bg [data-testid="accordion-content"] {
                    background-color: white !important;
                }
                
                /* Target any row, column, and container elements within the accordion */
                .white-bg .gr-form,
                .white-bg .gr-box,
                .white-bg .gr-row,
                .white-bg .gr-column,
                .white-bg .gr-panel,
                .white-bg .gr-padded,
                .white-bg .bg-gray-50,
                .white-bg .bg-gray-100,
                .white-bg .bg-gray-200 {
                    background-color: white !important;
                }
                
                /* Fix spacing in radio button group */
                .gradio-container .compact-radio {
                    max-width: 500px;
                    margin: 0 auto;
                }
                /* Center the label */
                .gradio-container .compact-radio > .label-wrap {
                    text-align: center;
                    justify-content: center;
                    margin-bottom: 8px; /* Reduce space between label and options */
                }
                /* Make options horizontal and centered */
                .gradio-container .compact-radio > .options {
                    display: flex;
                    flex-direction: row;
                    justify-content: center;
                    gap: 15px;
                    flex-wrap: nowrap;
                }
                /* Make each option more compact and match button height */
                .gradio-container .compact-radio > .options > .wrap {
                    flex: 0 0 auto;
                    min-width: 0;
                    margin: 0;
                }
                /* Style the radio button options to match button height */
                .gradio-container .compact-radio .gradio-radio {
                    height: 32px !important; /* Match sm button height */
                    padding: 0 12px !important; /* Match button padding */
                    border-radius: 4px !important; /* Match button border radius */
                    box-shadow: 0 1px 2px rgba(0, 0, 0, 0.05) !important; /* Light shadow like buttons */
                    display: flex !important;
                    align-items: center !important;
                    justify-content: center !important;
                }
                /* Make radio buttons smaller */
                .gradio-container .compact-radio input[type="radio"] {
                    transform: scale(0.8) !important; /* Make radio circles smaller */
                    margin-right: 4px !important; /* Reduce space between radio and label */
                }
                /* Reduce the label font size */
                .gradio-container .compact-radio label {
                    font-size: 0.9rem !important; /* Smaller text */
                    font-weight: normal !important;
                    white-space: nowrap !important;
                }
                </style>
                """, visible=False)
                
                # Use direct container without extra box for cleaner layout
                loader_type = gr.Radio(
                    label="Document Loader",
                    choices=["Docling (Enhanced)", "LangChain", "Mistral OCR"],
                    value="Docling (Enhanced)",
                    interactive=True,
                    info="Select the document loader to use for processing",
                    elem_classes="compact-radio"
                )
                
                with gr.Row(equal_height=True, elem_classes="center-items"):
                    process_btn = gr.Button("Process Documents", variant="primary", size="sm")
                    clear_btn = gr.Button("Clear", variant="stop", size="sm")
                
                progress_box = gr.HTML(
                    label="Status",
                    value="<div style='padding: 10px;'>Upload files and click Process to begin...</div>",
                    elem_id="progress-box"
                )
                
            # Add custom CSS for the progress box
            gr.Markdown("""
                <style>
                    /* Style for the progress box */
                    #progress-box {
                        min-height: 250px;
                        max-height: 500px;
                        overflow-y: auto;
                        background-color: #1a1a1a;
                        border-radius: 4px;
                        margin-top: 10px;
                        font-family: system-ui, -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
                    }
                    
                    /* Style for lists in the progress box */
                    #progress-box ul {
                        margin-top: 5px;
                        margin-bottom: 15px;
                        padding-left: 25px;
                    }
                    
                    #progress-box li {
                        margin-bottom: 3px;
                    }
                    
                    /* Make sure the progress bar is visible */
                    .progress-container {
                        width: 100% !important;
                        height: 20px !important;
                        background-color: #333 !important;
                        border-radius: 10px !important;
                        margin: 10px 0 !important;
                        overflow: hidden !important;
                        display: block !important;
                    }
                    
                    .progress-bar {
                        height: 100% !important;
                        background-color: #ff5500 !important;
                        border-radius: 10px !important;
                        transition: width 0.3s ease !important;
                        display: block !important;
                    }
                    
                    /* Ensure Gradio's progress bar is visible */
                    .gradio-container .progress {
                        display: block !important;
                        visibility: visible !important;
                        opacity: 1 !important;
                    }
                </style>
            """)

            # Create a container for the chat interface
            with gr.Column():
                # Add a state component to store chat history for other components to access
                chat_history_state = gr.State([])
                chat = gr.Chatbot(type="messages")
                msg = gr.Textbox(label="Message")
                with gr.Row():
                    submit = gr.Button("Submit", variant="huggingface", size="sm")
                    clear = gr.Button("Clear", variant="stop", size="sm")

                # Add example questions
                gr.Examples(
                    examples=chat_config.example_questions,
                    inputs=msg
                )

            # Vector Visualization Accordion
            with gr.Accordion("Vector Store Visualization", open=False):
                with gr.Row():
                    visualize_btn = gr.Button("Generate Visualization", variant="huggingface", size="sm")
                    plot_status = gr.Textbox(
                        label="Visualization Status",
                        placeholder="Click Generate Visualization to begin...",
                        interactive=False
                    )
                
                # Center the plot using a container with CSS
                with gr.Column(elem_classes="center-plot"):
                    # Plotly output component
                    plot_output = gr.Plot(
                        label="Vector Store Visualization",
                        show_label=True,
                        container=True,
                        elem_classes="plot-container"
                    )

            # Add custom CSS for centering
            gr.Markdown("""
                <style>
                    /* Center the plot container */
                    .center-plot {
                        display: flex;
                        justify-content: center;
                        align-items: center;
                        width: 100%;
                        min-height: 700px;  /* Add minimum height */
                    }
                    
                    /* Style the plot container */
                    .plot-container {
                        width: 100%;
                        max-width: 1200px;
                        margin: 0 auto;
                    }
                    
                    /* Center the Plotly plot itself */
                    .plot-container > div {
                        display: flex;
                        justify-content: center;
                        width: 100%;
                    }
                    
                    /* Ensure the SVG is centered */
                    .js-plotly-plot {
                        margin: 0 auto !important;
                    }
                    
                    /* Add responsive behavior */
                    @media (max-width: 768px) {
                        .plot-container {
                            max-width: 100%;
                            padding: 10px;
                        }
                    }
                </style>
            """)
            
            # Chat History Conceptual Diagram Accordion
            with gr.Accordion("Chat History Conceptual Diagram", open=False, elem_id="chat-diagram-accordion"):
                with gr.Row():
                    create_diagram_btn = gr.Button("Generate Conceptual Diagram", variant="primary", size="sm")
                    diagram_status = gr.Textbox(
                        label="Diagram Status",
                        placeholder="Click Generate Conceptual Diagram to begin...",
                        interactive=False
                    )
                
                # Add radio buttons for diagram renderer selection
                with gr.Row():
                    diagram_renderer = gr.Radio(
                        choices=["Mermaid.js (Default)", "streamlit_mermaid", "mkdocs-mermaid2", "PyMdown Extension"],
                        value="Mermaid.js (Default)",
                        label="Diagram Renderer",
                        info="Select the library to render the conceptual diagram",
                        interactive=True
                    )
                
                # Container for the diagram output
                with gr.Column(elem_classes="center-diagram"):
                    # Create the HTML component for diagram output
                    diagram_output = gr.HTML(
                        label="Chat Conceptual Diagram",
                        show_label=True,
                        container=True,
                        elem_classes="diagram-container"
                    )
            
            # Add custom CSS for the diagram container
            gr.HTML("""
                <style>
                    /* Center the diagram container */
                    .center-diagram {
                        display: flex;
                        justify-content: center;
                        align-items: center;
                        width: 100%;
                        min-height: 500px;
                    }
                    
                    /* Style the diagram container */
                    .diagram-container {
                        width: 100%;
                        max-width: 1000px;
                        margin: 0 auto;
                    }
                </style>
            """, visible=False)

            # Event handlers
            async def chat_response(message, history, history_state):
                history = history or []
                history_state = history_state or []
                
                # Add user message to history immediately using messages format
                history.append({"role": "user", "content": message})
                history.append({"role": "assistant", "content": ""})
                
                # Update the history state
                history_state = history.copy()
                
                # Create a generator for streaming responses
                try:
                    # First yield the history with empty response to show user message immediately
                    yield history, history_state
                    
                    # Get the full response (non-streaming first to debug)
                    full_response = ""
                    
                    # Stream the response
                    async for partial_response in chat_interface.stream_chat(message, history[:-1]):
                        # Update the last assistant message with the current content
                        full_response = partial_response['content']
                        history[-1] = {"role": "assistant", "content": full_response}
                        history_state[-1] = {"role": "assistant", "content": full_response}
                        
                        # Yield the updated history and state
                        yield history, history_state
                    
                except Exception as e:
                    logger.error(f"Error in chat response: {str(e)}", exc_info=True)
                    history[-1] = {"role": "assistant", "content": f"Error: {str(e)}"}
                    yield history

            async def process_documents(loader_type):
                try:
                    logger.info("Starting document processing...")
                    print("\n=== Document Processing Started ===")
                    
                    # Show loader type in progress box
                    status_html = f"<div style='padding: 10px;'><b>\ud83d\udcda Document Loader:</b> {loader_type}<br/><br/>Processing documents...</div>"
                    yield status_html
                    
                    # Fix: Create config objects first
                    postgres_config = PostgresConfig(
                        connection_string=chat_interface.postgres_config.connection_string,
                        pre_delete_collection=False,
                        drop_existing=False
                    )
                    
                    # Determine which loader to use based on selection
                    use_docling = False
                    use_mistral = False
                    loader_name = "LangChain"
                    
                    if loader_type == "Docling (Enhanced)":
                        use_docling = True
                        loader_name = "Docling (Enhanced)"
                    elif loader_type == "Mistral OCR":
                        use_mistral = True
                        loader_name = "Mistral OCR"
                        
                    # Log the selected loader
                    logger.info(f"Using document loader: {loader_name}")
                    print(f"\n=== üìö Document Loader: {loader_name} ===\n")
                    
                    processor_config = ProcessorConfig(
                        chunk_size=500,
                        chunk_overlap=50,
                        vector_store_type="postgres",
                        postgres_config=postgres_config,
                        batch_size=50,
                        max_workers=8,
                        db_pool_size=20,
                        openai_api_key=OPENAI_API_KEY,
                        # Set loader options based on user selection
                        use_docling=use_docling,
                        docling_artifacts_path=os.getenv('DOCLING_ARTIFACTS_PATH'),
                        docling_enable_remote=os.getenv('DOCLING_ENABLE_REMOTE', '').lower() in ('true', '1', 'yes'),
                        docling_use_cache=os.getenv('DOCLING_USE_CACHE', 'true').lower() in ('true', '1', 'yes'),
                        use_mistral=use_mistral,
                        mistral_api_key=os.getenv('MISTRAL_API_KEY'),
                        mistral_ocr_model=os.getenv('MISTRAL_OCR_MODEL', 'mistral-ocr-latest'),
                        mistral_include_images=os.getenv('MISTRAL_INCLUDE_IMAGES', '').lower() in ('true', '1', 'yes')
                    )
                    
                    # Initialize document processor with config object
                    processor = DocumentProcessor(config=processor_config)
                    
                    # Initialize database
                    await processor.initialize_database()
                    
                    # Get all files in documents directory
                    all_files = list(chat_interface.documents_dir.glob('*.*'))
                    print(f"Found {len(all_files)} files to process")
                    
                    # Process files with checksum verification
                    total_chunks = 0
                    processed_files = []
                    skipped_files = []
                    
                    # First, get all existing checksums in a separate session
                    existing_checksums = {}
                    existing_filenames = {}
                    
                    # Update progress box with more info
                    status_html = f"<div style='padding: 10px;'><b>\ud83d\udcda Document Loader:</b> {loader_type}<br/><br/>Checking {len(all_files)} files in database...</div>"
                    yield status_html
                    
                    async with chat_interface.async_session() as session:
                        # Get all existing documents
                        result = await session.execute(select(DocumentModel))
                        existing_docs = result.scalars().all()
                        
                        for doc in existing_docs:
                            existing_checksums[doc.checksum] = doc.id
                            existing_filenames[doc.filename] = doc.checksum
                        
                    print(f"\n=== Existing Documents in Database ===")
                    print(f"Found {len(existing_checksums)} documents in database")
                    
                    # Now process each file individually without an outer session
                    for file_path in all_files:
                        try:
                            # Calculate checksum
                            file_checksum = chat_interface.calculate_file_checksum(str(file_path))
                            print(f"\n===== Checking file: {file_path.name} =====")
                            print(f"Calculated checksum: {file_checksum}")
                            
                            # Check if file exists in database by checksum
                            checksum_exists = file_checksum in existing_checksums
                            print(f"Checksum exists in database? {checksum_exists}")
                            
                            if checksum_exists:
                                print(f"‚è© Skipping {file_path.name} - found matching checksum in database")
                                logger.info(f"Skipping {file_path.name} - already exists with checksum {file_checksum}")
                                skipped_files.append(file_path.name)
                                continue
                            
                            # Also check by filename as a fallback
                            if file_path.name in existing_filenames:
                                db_checksum = existing_filenames[file_path.name]
                                print(f"‚ö†Ô∏è File {file_path.name} exists in DB but with different checksum!")
                                print(f"  DB checksum: {db_checksum[:8]}...")
                                print(f"  File checksum: {file_checksum[:8]}...")
                                # Skip if filename matches but checksum doesn't
                                skipped_files.append(file_path.name)
                                continue
                            
                            # Process file - let the processor handle its own session
                            print(f"üîÑ Processing {file_path.name}...")
                            logger.info(f"Processing {file_path.name}")
                            chunks = await chat_interface.process_single_file(file_path, processor_config)
                            
                            if chunks:
                                total_chunks += len(chunks)
                                processed_files.append(file_path.name)
                                print(f"‚úÖ Processed {file_path.name} - created {len(chunks)} chunks")
                                
                                # Update our local cache of checksums and filenames
                                existing_checksums[file_checksum] = True
                                existing_filenames[file_path.name] = file_checksum
                            
                        except Exception as e:
                            print(f"‚ùå Error processing {file_path.name}: {str(e)}")
                            logger.error(f"Error processing {file_path.name}: {str(e)}")
                            continue
                    
                    # Create HTML status message with loader info
                    html_status = f"<div style='padding: 10px;'>"
                    html_status += f"<h3>‚úÖ Processing Complete</h3>"
                    
                    # Add document loader information
                    html_status += f"<p><b>üìö Document Loader:</b> {loader_type}</p>"
                    
                    # Add loader-specific configuration details
                    if use_docling:
                        html_status += f"<p><b>Docling Configuration:</b></p>"
                        html_status += "<ul>"
                        html_status += f"<li>Remote Processing: {os.getenv('DOCLING_ENABLE_REMOTE', 'false').lower() in ('true', '1', 'yes')}</li>"
                        html_status += f"<li>Cache Enabled: {os.getenv('DOCLING_USE_CACHE', 'true').lower() in ('true', '1', 'yes')}</li>"
                        html_status += "</ul>"
                    elif use_mistral:
                        html_status += f"<p><b>Mistral OCR Configuration:</b></p>"
                        html_status += "<ul>"
                        html_status += f"<li>Model: {os.getenv('MISTRAL_OCR_MODEL', 'mistral-ocr-latest')}</li>"
                        html_status += f"<li>Include Images: {os.getenv('MISTRAL_INCLUDE_IMAGES', 'false').lower() in ('true', '1', 'yes')}</li>"
                        html_status += "</ul>"
                    
                    # Add processing statistics
                    html_status += f"<p><b>Processing Summary:</b></p>"
                    html_status += "<ul>"
                    html_status += f"<li>Total files: {len(all_files)}</li>"
                    html_status += f"<li>Processed files: {len(processed_files)}</li>"
                    html_status += f"<li>Skipped files: {len(skipped_files)}</li>"
                    html_status += f"<li>Total chunks created: {total_chunks}</li>"
                    html_status += "</ul>"
                    
                    # List processed files if any
                    if processed_files:
                        html_status += f"<p><b>Files Processed:</b></p>"
                        html_status += "<ul>"
                        for file in processed_files:
                            html_status += f"<li>{file}</li>"
                        html_status += "</ul>"
                    
                    html_status += "</div>"
                    
                    # Also print to console
                    print(f"\n=== Processing Summary ===\n")
                    print(f"Document Loader: {loader_type}")
                    print(f"Total files: {len(all_files)}")
                    print(f"Processed files: {len(processed_files)}")
                    print(f"Skipped files: {len(skipped_files)}")
                    print(f"Total chunks created: {total_chunks}")
                    
                    # Use yield instead of return since we're in an async generator function
                    yield html_status
                    
                except Exception as e:
                    error_message = f"<div style='padding: 10px; color: #e74c3c;'><h3>‚ùå Error</h3><p>Error processing documents with {loader_type} loader: {str(e)}</p></div>"
                    logger.error(error_message, exc_info=True)
                    yield error_message

            # The generate_chat_diagram function is now implemented further below
                    
            async def generate_visualization():
                try:
                    plot_status.value = "Generating visualization... This may take a while."
                    
                    # Create async session
                    async with chat_interface.async_session() as session:
                        # Generate visualization
                        fig = await visualize_vector_store(session)
                        
                        return (
                            fig,
                            "Visualization generated successfully! Hover over points to see document details."
                        )
                except Exception as e:
                    error_msg = f"Error generating visualization: {str(e)}"
                    logger.error(error_msg, exc_info=True)
                    return (
                        None,
                        error_msg
                    )

            def clear_upload():
                return "<div style='padding: 10px;'>Upload files and click Process to begin...</div>"

            # Connect the chat components with proper Gradio streaming configuration
            submit.click(
                chat_response,
                inputs=[msg, chat, chat_history_state],
                outputs=[chat, chat_history_state],
                api_name="submit",
            ).then(
                lambda: "",  # Clear the message box after submission
                None,
                msg
            )

            # Also enable streaming for the Enter key
            msg.submit(
                chat_response,
                inputs=[msg, chat, chat_history_state],
                outputs=[chat, chat_history_state],
                api_name="submit_msg",
            ).then(
                lambda: "",  # Clear the message box after submission
                None,
                msg
            )

            # Clear both the chat display and history state when clearing
            clear.click(lambda: (None, []), None, [chat, chat_history_state])

            # Connect file upload components
            upload_button.upload(
                fn=chat_interface.handle_file_upload,
                inputs=upload_button,
                outputs=progress_box,
            )
            
            process_btn.click(
                fn=chat_interface.process_documents,
                inputs=loader_type,
                outputs=progress_box,
                show_progress=True,
            )
            
            clear_btn.click(
                fn=clear_upload,
                inputs=None,
                outputs=progress_box,
            )
            
            # Connect visualization button
            visualize_btn.click(
                fn=generate_visualization,
                inputs=None,
                outputs=[plot_output, plot_status],
            )
            
            # Define function to generate conceptual diagram from chat history using Mermaid
            async def generate_chat_diagram(history, renderer="Mermaid.js (Default)"):
                try:
                    diagram_status.value = "Generating conceptual diagram... Please wait."
                    
                    # Check if chat history exists
                    if not history or len(history) == 0:
                        return None, "No chat history available. Please have a conversation first."
                    
                    # Format chat history for the prompt
                    chat_history_text = ""
                    for msg in history:
                        role = msg.get("role", "")
                        content = msg.get("content", "")
                        if role and content:
                            chat_history_text += f"{role.capitalize()}: {content}\n\n"
                    
                    if not chat_history_text.strip():
                        diagram_status.value = "No chat history available to analyze."
                        return None, "No chat history available to analyze."
                    
                    # Create the prompt for the LLM to analyze the chat history
                    # Use the diagram template from config
                    prompt = prompt_config.diagram_template.format(chat_history=chat_history_text)
                    
                    # Call the LLM to analyze the chat history using a structured message
                    from langchain_core.messages import HumanMessage
                    human_message = HumanMessage(content=prompt)
                    analysis_response = await chat_interface.llm.ainvoke([human_message])
                    
                    # Extract the Mermaid diagram from the response
                    try:
                        # Get the content from the response
                        if hasattr(analysis_response, 'content'):
                            content = analysis_response.content
                        else:
                            content = str(analysis_response)
                        
                        # Log the full LLM response for debugging
                        print("\n==== FULL LLM RESPONSE ====")
                        print(content)
                        print("==== END LLM RESPONSE ====")
                            
                        # Try to find Mermaid code in the response
                        mermaid_start = content.find('```mermaid')
                        mermaid_end = content.rfind('```')
                        
                        # If we can't find mermaid code with the standard markers, try alternative formats
                        if mermaid_start == -1:
                            # Try without the backticks
                            mermaid_start = content.find('mermaid')
                            if mermaid_start != -1:
                                # Find the end of the diagram by looking for common diagram types
                                diagram_types = ['flowchart', 'graph', 'mindmap', 'sequenceDiagram', 'classDiagram']
                                for diagram_type in diagram_types:
                                    if content[mermaid_start:].find(diagram_type) != -1:
                                        mermaid_start = mermaid_start + content[mermaid_start:].find(diagram_type)
                                        break
                        
                        if mermaid_start != -1 and mermaid_end != -1:
                            # Extract the Mermaid code (excluding the ```mermaid and ``` markers)
                            mermaid_start += len('```mermaid')
                            mermaid_code = content[mermaid_start:mermaid_end].strip()
                            
                            # Clean up the code to ensure it's valid Mermaid syntax
                            # Remove any additional markdown formatting that might be present
                            mermaid_code = mermaid_code.replace('\\n', '\n').replace('\\t', '\t')
                            
                            # Ensure the mermaid code starts with a valid diagram type
                            if not any(mermaid_code.strip().startswith(prefix) for prefix in ['graph', 'flowchart', 'sequenceDiagram', 'classDiagram', 'gantt', 'pie', 'erDiagram', 'mindmap']):
                                # Add a default graph type if missing
                                mermaid_code = 'graph TD\n' + mermaid_code
                                
                            # Make sure the code is properly formatted with line breaks
                            # This is critical for Mermaid.js to parse the syntax correctly
                            if ';' in mermaid_code and '\n' not in mermaid_code:
                                # If we have semicolons but no line breaks, add them
                                mermaid_code = mermaid_code.replace(';', ';\n')
                            # FINAL FIX: RETAIN EXACT LLM DIAGRAM STRUCTURE
                            # Only ensure a valid diagram type exists, nothing else
                            
                            # 1. Check if diagram already has a valid type
                            valid_diagram_type = any(mermaid_code.strip().startswith(prefix) for prefix in ['graph', 'flowchart', 'sequenceDiagram', 'classDiagram', 'gantt', 'pie', 'erDiagram', 'mindmap'])
                            
                            # 2. If no diagram type exists, add a simple one
                            if not valid_diagram_type:
                                # Add the most compatible diagram type
                                mermaid_code = 'graph TD\n' + mermaid_code
                            
                            # Preserve the original diagram structure from the LLM
                            # Only clean up whitespace and ensure proper line breaks
                            lines = mermaid_code.split('\n')
                            processed_lines = []
                            
                            for line in lines:
                                if line.strip():
                                    # Keep the original line structure intact
                                    processed_lines.append(line.strip())
                            
                            mermaid_code = '\n'.join(processed_lines)
                            
                            # Clean up the code to ensure proper formatting
                            lines = mermaid_code.split('\n')
                            cleaned_lines = [line.strip() for line in lines if line.strip()]
                            mermaid_code = '\n'.join(cleaned_lines)
                        else:
                            # If no Mermaid markers found, use the whole content as it might be just the diagram code
                            mermaid_code = content.strip()
                            
                            # Check if the content starts with a valid Mermaid diagram type
                            valid_starts = ['graph', 'flowchart', 'mindmap', 'sequenceDiagram', 'classDiagram', 'gantt', 'pie', 'erDiagram']
                            # Normalize whitespace for better detection
                            mermaid_code_normalized = ' '.join(mermaid_code.split())
                            
                            # If it doesn't start with a valid Mermaid syntax, handle it
                            if not any(mermaid_code_normalized.startswith(start) for start in valid_starts):
                                # Check if it's a Plotly figure (the error we're seeing)
                                if 'Figure(' in mermaid_code or "'layout':" in mermaid_code or "'data':" in mermaid_code or "'type': 'scatter'" in mermaid_code or "annotations" in mermaid_code:
                                    print("Detected Plotly figure, converting to proper Mermaid diagram")
                                    # Extract any meaningful information from the Plotly figure if possible
                                    title = "Chat History Conceptual Diagram"
                                    if "'title'" in mermaid_code:
                                        try:
                                            title_start = mermaid_code.find("'title'")
                                            title_content = mermaid_code[title_start:].split(":", 1)[1].strip()
                                            if "'text'" in title_content[:30]:
                                                title_text = title_content.split("'text':", 1)[1].strip()
                                                if title_text.startswith("'") and "'" in title_text[1:]:
                                                    title = title_text.split("'", 2)[1]
                                        except Exception as e:
                                            print(f"Error extracting title: {e}")
                                            
                                    # Create an example Mermaid diagram based on infectious disease management
                                    # This provides a better user experience than just an error message
                                    mermaid_code = f"graph TD\n    A(({title})):::mainTopic --> B[Public Health Considerations]:::pubHealth\n    A --> C[Testing Strategies]:::testing\n    A --> D[Epidemiology]:::epidemiology\n    A --> E[Community Response]:::community\n\n    B --> B1[Surveillance]:::pubHealth\n    B --> B2[Health Policy]:::pubHealth\n    C --> C1[Diagnostic Methods]:::testing\n    C --> C2[Quality Assurance]:::testing\n    D --> D1[Transmission Dynamics]:::epidemiology\n    D --> D2[Population Impact]:::epidemiology\n    E --> E1[Public Awareness]:::community\n    E --> E2[Resource Allocation]:::community\n\n    classDef mainTopic fill:#5d87fe,stroke:#333,stroke-width:2px;\n    classDef pubHealth fill:#ff9eb1,stroke:#333;\n    classDef testing fill:#d5f5c0,stroke:#333;\n    classDef epidemiology fill:#c5eafa,stroke:#333;\n    classDef community fill:#f9d9ab,stroke:#333;\n"
                                else:
                                    raise ValueError("Response does not contain a valid Mermaid diagram")
                    except Exception as e:
                        import traceback
                        error_details = traceback.format_exc()
                        print(f"Error extracting Mermaid diagram: {str(e)}\n{error_details}")
                        diagram_status.value = f"Error extracting Mermaid diagram: {str(e)}"
                        return None, f"Error extracting Mermaid diagram: {str(e)}"
                    
                    # Create a simple HTML page with the Mermaid diagram based on the selected renderer
                    # This approach creates a full HTML page that can be displayed in an iframe
                    
                    # Create the base mermaid div with proper formatting and error handling
                    # Make sure the mermaid code is properly formatted for all renderers
                    clean_mermaid_code = mermaid_code.strip()
                    
                    # Validate the mermaid code to ensure it starts with a valid diagram type
                    valid_starts = ['graph', 'flowchart', 'sequenceDiagram', 'classDiagram', 'gantt', 'pie', 'erDiagram']
                    mermaid_code_normalized = ' '.join(clean_mermaid_code.split())
                    
                    # Check for diagram types that might not be properly supported in all renderers
                    is_mindmap = mermaid_code_normalized.startswith('mindmap')
                    is_graph = mermaid_code_normalized.startswith('graph')
                    is_flowchart = mermaid_code_normalized.startswith('flowchart')
                    
                    # Convert flowchart to graph for better compatibility with mermaid 9.1.7
                    if is_flowchart:
                        print("Converting flowchart to graph for better compatibility with mermaid.js 9.1.7")
                        clean_mermaid_code = clean_mermaid_code.replace('flowchart', 'graph', 1)
                    
                    # Always store the original code before any modifications
                    original_mermaid_code = clean_mermaid_code
                    
                    # Convert mindmaps to flowcharts for better compatibility across all renderers
                    # This is necessary because mindmap syntax is only supported in newer mermaid versions
                    if is_mindmap:
                        print(f"Converting mindmap to flowchart for compatibility with {renderer}")
                        
                        # Extract the mindmap content to preserve the structure as much as possible
                        lines = clean_mermaid_code.split('\n')
                        # Skip the first line (mindmap declaration)
                        content_lines = [line for line in lines[1:] if line.strip()]
                        
                        # Create a flowchart with similar structure
                        # Use graph TD instead of flowchart TD for better compatibility with mermaid 9.1.7
                        flowchart = ["graph TD"]
                        
                        # Process the root node if it exists
                        root_node = None
                        for i, line in enumerate(content_lines):
                            if '((' in line and '))' in line and i == 0:
                                # This is likely a root node
                                root_text = line.strip()
                                # Extract text between (( and ))
                                root_content = root_text[root_text.find('((')+2:root_text.find('))')]
                                root_node = f"    A[{root_content}]"
                                flowchart.append(root_node)
                                break
                        
                        # If no root node was found, create a default one
                        if not root_node:
                            flowchart.append("    A[Chat History]")
                        
                        # Parse the mindmap structure and preserve all information
                        # Track indentation to determine parent-child relationships
                        node_counter = 0
                        node_map = {}
                        connections = []
                        
                        # First pass: identify all nodes
                        for i, line in enumerate(content_lines):
                            if not line.strip():
                                continue
                                
                            # Skip the root node as we've already processed it
                            if i == 0 and '((' in line and '))' in line:
                                continue
                                
                            # Calculate indentation level (number of spaces)
                            indent = len(line) - len(line.lstrip())
                            text = line.strip()
                            
                            # Create a unique node ID
                            node_id = f"node{node_counter}"
                            node_counter += 1
                            
                            # Store the node with its indentation level
                            node_map[node_id] = {
                                'text': text,
                                'indent': indent,
                                'level': indent // 2  # Assuming 2 spaces per level
                            }
                        
                        # Second pass: create connections based on indentation
                        prev_level_nodes = {0: 'A'}  # Root node is A
                        
                        for node_id, node_info in node_map.items():
                            level = node_info['level']
                            text = node_info['text']
                            
                            # Find the parent node (closest node with lower indentation)
                            parent_level = max([l for l in prev_level_nodes.keys() if l < level], default=0)
                            parent_id = prev_level_nodes[parent_level]
                            
                            # Add this node to the flowchart
                            flowchart.append(f"    {node_id}[{text}]")
                            
                            # Connect to parent
                            flowchart.append(f"    {parent_id} --> {node_id}")
                            
                            # Update the previous level nodes
                            prev_level_nodes[level] = node_id
                            
                            # Remove any higher levels (as they can't be parents anymore)
                            higher_levels = [l for l in prev_level_nodes.keys() if l > level]
                            for l in higher_levels:
                                del prev_level_nodes[l]
                                
                        # If no nodes were processed, add some default connections
                        if not node_map:
                            flowchart.append("    A --> B[Topics]")
                            flowchart.append("    B --> C[Insights]")
                            flowchart.append("    A --> D[Questions]")
                            flowchart.append("    D --> E[Answers]")
                        
                        # Join the flowchart lines
                        clean_mermaid_code = "\n".join(flowchart)
                    elif not any(mermaid_code_normalized.startswith(start) for start in valid_starts) and not is_mindmap:
                        print("Warning: Mermaid code doesn't start with a valid diagram type. Using fallback diagram.")
                        # Provide a fallback diagram if the code doesn't start with a valid diagram type
                        clean_mermaid_code = "graph TD\n    A[Chat History] --> B[Topics]\n    B --> C[Insights]\n    A --> D[Questions]\n    D --> E[Answers]"
                    
                    # Add console logging for debugging
                    print(f"Mermaid code being used: {clean_mermaid_code[:100]}...")
                    print(f"Selected renderer: {renderer}")
                    
                    # Print the full mermaid code for cross-checking
                    print("\n==== FULL MERMAID CODE ====")
                    print(clean_mermaid_code)
                    print("==== END MERMAID CODE ====")
                    
                    # For the default renderer, we'll use a div with the class 'mermaid'
                    # For other renderers, we'll use a pre-rendered SVG approach which is more reliable
                    # across different mermaid versions
                    
                    # Create a div element with mermaid class for proper rendering
                    # Using div instead of pre for better compatibility with mermaid.js
                    mermaid_div = f'''
                    <div id="mermaid-wrapper">
                        <div class="mermaid" id="mermaid-diagram-container">
{clean_mermaid_code}
                        </div>
                    </div>
                    '''
                    
                    # For non-default renderers, we'll use a different approach with pre-initialization
                    # This helps ensure compatibility across different mermaid versions
                    # Use a safer approach to handle JavaScript escaping in f-strings
                    escaped_mermaid_code = clean_mermaid_code.replace('`', r'\`').replace("'", r"\'")
                    mermaid_pre_init = f'''
                    <script>
                        // Pre-initialize mermaid with the code
                        try {{
                            console.log("Mermaid code being processed:");
                            console.log(`{escaped_mermaid_code}`);
                        }} catch (e) {{
                            console.error("Error logging mermaid code:", e);
                        }}
                    </script>
                    <div id="mermaid-error" style="display:none;" class="error-message"></div>
                    '''
                    
                    # Generate HTML content based on the selected renderer
                    # For the default renderer with Mermaid.js 9.1.7, we can use flowchart for all diagrams
                    # This ensures consistent rendering and avoids syntax errors
                    if is_mindmap or is_graph:
                        print("Ensuring diagram compatibility with mermaid.js 9.1.7")
                        # We'll keep the converted flowchart for all renderers to ensure consistency
                        # This prevents syntax errors that might occur with mindmap or graph syntax
                    
                    if renderer == "Mermaid.js (Default)":
                        # Default Mermaid.js rendering - using a more reliable approach
                        html_content = '''
                        <!DOCTYPE html>
                        <html>
                        <head>
                            <script src="https://cdn.jsdelivr.net/npm/mermaid@8.8.0/dist/mermaid.min.js"></script>
                            <!-- Using version 8.8.0 which is compatible with all renderers -->
                            <script>
                                // Configuration for Mermaid
                                // Minimal configuration for maximum compatibility
                                mermaid.initialize({
                                    startOnLoad: true
                                });
                            </script>
                            <style>
                                body { 
                                    font-family: Arial, sans-serif; 
                                    margin: 0; 
                                    padding: 20px; 
                                    background-color: white;
                                }
                                h2 { 
                                    color: #333; 
                                    text-align: center; 
                                    margin-bottom: 20px;
                                }
                                .diagram-container { 
                                    width: 100%; 
                                    max-width: 950px; 
                                    margin: 0 auto; 
                                    padding: 20px; 
                                    background-color: #f8f8f8; 
                                    border-radius: 8px;
                                    min-height: 400px;
                                }
                                .error-message {
                                    color: #d32f2f;
                                    text-align: center;
                                    padding: 15px;
                                    border: 1px solid #ffcdd2;
                                    border-radius: 4px;
                                    background-color: #ffebee;
                                    margin: 20px 0;
                                }
                            </style>
                        </head>
                        <body>
                            <h2>Conceptual Diagram of Chat History</h2>
                            <div class="diagram-container">
                                <div id="mermaid-diagram">
                                    <div class="mermaid">
{clean_mermaid_code}
                                    </div>
                                </div>
                                <div id="mermaid-error" style="display:none;color:red;padding:10px;border:1px solid #ddd;"></div>
                            </div>
                            <script>
                                // Add error handling for Mermaid rendering
                                window.addEventListener('error', function(e) {
                                    if (e.message && e.message.includes('mermaid')) {
                                        console.error('Mermaid error:', e);
                                        var errorDiv = document.getElementById('mermaid-error');
                                        if (errorDiv) {
                                            errorDiv.style.display = 'block';
                                            errorDiv.innerHTML = 'Error rendering the diagram. The syntax may be invalid: ' + e.message;
                                        } else {
                                            document.querySelector('.diagram-container').innerHTML += 
                                                '<div class="error-message">Error rendering the diagram. The syntax may be invalid.</div>';
                                        }
                                    }
                                });
                                
                                // Initialize mermaid after DOM is loaded
                                document.addEventListener('DOMContentLoaded', function() {
                                    console.log('DOM loaded, initializing mermaid...');
                                    try {
                                        if (typeof mermaid !== 'undefined') {
                                            // First make sure the mermaid code is visible in the DOM for debugging
                                            console.log('Mermaid code:', document.querySelector('.mermaid')?.textContent || 'No mermaid element found');
                                            
                                            // Simple rendering approach - let mermaid handle it automatically
                                            try {
                                                console.log('Letting mermaid handle rendering with startOnLoad: true');
                                                
                                                // Force mermaid to reprocess after a short delay
                                                setTimeout(function() {
                                                    try {
                                                        console.log('Forcing mermaid to reprocess diagrams...');
                                                        // Simplest possible initialization for v8.8.0
                                                        try {
                                                            mermaid.init();
                                                            console.log('Mermaid initialized successfully');
                                                        } catch (error) {
                                                            console.error('Mermaid initialization failed:', error);
                                                            document.getElementById('mermaid-error').style.display = 'block';
                                                            document.getElementById('mermaid-error').innerHTML = 'Error rendering diagram: ' + error.message;
                                                        }
                                                    } catch (e) {
                                                        console.error('Error during forced reprocessing:', e);
                                                    }
                                                }, 500);
                                                // Mermaid will automatically process diagrams on page load
                                                // No need for manual rendering
                                            } catch (setupError) {
                                                console.error('Error during mermaid setup:', setupError);
                                                document.getElementById('mermaid-error').style.display = 'block';
                                                document.getElementById('mermaid-error').innerHTML = 'Error setting up diagram renderer: ' + setupError.message;
                                            }
                                        }
                                    } catch (e) {
                                        console.error('Mermaid initialization error:', e);
                                        var errorDiv = document.getElementById('mermaid-error');
                                        if (errorDiv) {
                                            errorDiv.style.display = 'block';
                                            errorDiv.innerHTML = 'Error initializing the diagram renderer: ' + e.message;
                                        } else {
                                            console.error('Error element not found');
                                            document.querySelector('.diagram-container').innerHTML += 
                                                '<div style="color:red;padding:10px;border:1px solid #ddd;">Error initializing the diagram renderer: ' + e.message + '</div>';
                                        }
                                    }
                                });
                            </script>
                        </body>
                        </html>
                        '''
                    
                    elif renderer == "streamlit_mermaid":
                        # Actual streamlit_mermaid rendering
                        # This simulates how streamlit_mermaid would render the diagram
                        # with the streamlit-specific container and styling
                        
                        # Create a streamlit-style container for the mermaid diagram
                        # Use the same mermaid_div approach as the default renderer for consistency
                        html_content = '''
                        <!DOCTYPE html>
                        <html>
                        <head>
                            <script src="https://cdn.jsdelivr.net/npm/mermaid@8.8.0/dist/mermaid.min.js"></script>
                            <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono&family=IBM+Plex+Sans:wght@400;600&display=swap" rel="stylesheet">
                            <script>
                                // Configuration specific to streamlit_mermaid
                                mermaid.initialize({
                                    startOnLoad: false,  // We'll manually initialize for better control
                                    theme: 'neutral',
                                    logLevel: 'error',
                                    securityLevel: 'loose',
                                    fontFamily: '"IBM Plex Sans", sans-serif',
                                    flowchart: {
                                        curve: 'linear',
                                        htmlLabels: true,
                                        useMaxWidth: true
                                    },
                                    sequence: {
                                        useMaxWidth: true,
                                        diagramMarginX: 50,
                                        diagramMarginY: 10,
                                        boxMargin: 10,
                                        mirrorActors: false
                                    },
                                    gantt: {
                                        useMaxWidth: true,
                                        topPadding: 30,
                                        leftPadding: 75
                                    }
                                });
                            </script>
                            <style>
                                /* Streamlit-specific styling */
                                body { 
                                    font-family: "IBM Plex Sans", sans-serif; 
                                    margin: 0; 
                                    padding: 0; 
                                    background-color: #f0f2f6;
                                }
                                
                                .streamlit-container { 
                                    max-width: 100%;
                                    padding: 1rem;
                                    margin: 0 auto;
                                    background-color: white;
                                    border-radius: 0.5rem;
                                    box-shadow: 0 1px 2px rgba(0,0,0,0.05);
                                }
                                
                                .streamlit-header {{ 
                                    color: #262730; 
                                    font-size: 1.25rem;
                                    font-weight: 600;
                                    margin-bottom: 1rem;
                                    padding-bottom: 0.5rem;
                                    border-bottom: 1px solid #f0f2f6;
                                }}
                                
                                .streamlit-mermaid {{
                                    width: 100%;
                                    min-height: 400px;
                                    display: flex;
                                    justify-content: center;
                                    align-items: center;
                                    padding: 1rem 0;
                                }}
                                
                                .streamlit-mermaid svg {
                                    max-width: 100%;
                                }
                                
                                .streamlit-footer {
                                    margin-top: 1rem;
                                    padding-top: 0.5rem;
                                    border-top: 1px solid #f0f2f6;
                                    font-size: 0.8rem;
                                    color: #888;
                                    text-align: center;
                                }
                                
                                .error-message {
                                    color: #ff4b4b;
                                    background-color: #ffebee;
                                    border: 1px solid #ffcdd2;
                                    border-radius: 0.25rem;
                                    padding: 0.75rem;
                                    margin: 1rem 0;
                                    text-align: center;
                                }
                                
                                /* Streamlit-specific mermaid overrides */
                                .mermaid .label { 
                                    font-family: "IBM Plex Sans", sans-serif !important;
                                }
                                
                                .mermaid .node rect, .mermaid .node circle, .mermaid .node ellipse, .mermaid .node polygon, .mermaid .node path {
                                    fill: #f8f9fa;
                                    stroke: #e6e9ef;
                                    stroke-width: 1px;
                                }
                                
                                .mermaid .edgePath .path {
                                    stroke: #5c6470 !important;
                                    stroke-width: 1.5px;
                                }
                                
                                .mermaid .edgeLabel {{
                                    background-color: #ffffff;
                                    color: #262730;
                                }}
                                
                                .mermaid .cluster rect {{
                                    fill: #f8f9fa !important;
                                    stroke: #e6e9ef !important;
                                    stroke-width: 1px !important;
                                }}
                            </style>
                        </head>
                        <body>
                            <div class="streamlit-container">
                                <div class="streamlit-header">Conceptual Diagram of Chat History</div>
                                <div class="streamlit-mermaid">
                                    <pre class="mermaid">
{clean_mermaid_code}
                                    </pre>
                                </div>
                                {mermaid_pre_init}
                                <div class="streamlit-footer">
                                    Rendered with streamlit_mermaid
                                </div>
                            </div>
                            
                            <script>
                                // Add error handling for Mermaid rendering
                                window.addEventListener('error', function(e) {{
                                    if (e.message && e.message.includes('mermaid')) {{
                                        console.error('Mermaid error:', e);
                                        document.querySelector('.streamlit-mermaid').innerHTML += 
                                            '<div class="error-message">Error rendering the diagram. The syntax may be invalid.</div>';
                                    }}}}
                                }});
                                
                                // Add streamlit-specific rendering behavior
                                document.addEventListener('DOMContentLoaded', function() {
                                    // Force re-render after a short delay to ensure proper sizing
                                    setTimeout(function() {
                                        if (typeof mermaid !== 'undefined') {
                                            try {
                                                // Try to render the diagram with a slight delay to ensure DOM is ready
                                                setTimeout(function() {
                                                    try {
                                                        console.log('Attempting to render mermaid diagram...');
                                                        mermaid.init(undefined, document.querySelectorAll('.mermaid'));
                                                        console.log('Mermaid rendering complete');
                                                    } catch (renderError) {
                                                        console.error('Mermaid rendering error:', renderError);
                                                        document.getElementById('mermaid-error').style.display = 'block';
                                                        document.getElementById('mermaid-error').innerHTML = 'Error rendering diagram: ' + renderError.message;
                                                    }
                                                }, 100);
                                            } catch (e) {
                                                console.error('Mermaid re-initialization error:', e);
                                                document.querySelector('.streamlit-mermaid').innerHTML += 
                                                    '<div class="error-message">Error initializing the diagram renderer.</div>';
                                            }
                                        }
                                    }, 200);
                                }});
                            </script>
                        </body>
                        </html>
                        '''
                    
                    elif renderer == "mkdocs-mermaid2":
                        # Actual mkdocs-mermaid2 style rendering
                        # This simulates how mkdocs-mermaid2 would render the diagram
                        # with the mkdocs-specific container and styling
                        
                        # Clean the mermaid code (remove leading/trailing whitespace)
                        clean_mermaid_code = mermaid_code.strip()
                        
                        # Create an mkdocs-style container for the mermaid diagram
                        html_content = '''
                        <!DOCTYPE html>
                        <html>
                        <head>
                            <script src="https://cdn.jsdelivr.net/npm/mermaid@9.1.7/dist/mermaid.min.js"></script>
                            <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500&family=Roboto+Mono&display=swap" rel="stylesheet">
                            <script>
                                // Configuration specific to mkdocs-mermaid2
                                mermaid.initialize({
                                    startOnLoad: false,  // We'll manually initialize for better control
                                    theme: 'dark',
                                    logLevel: 'error',
                                    securityLevel: 'loose',
                                    fontFamily: 'Roboto, "Helvetica Neue", Helvetica, Arial, sans-serif',
                                    themeCSS: '.node rect { fill: #2d3143; stroke: #58687e; } .edgeLabel { color: #f8f8f2; } .edgePath .path { stroke: #58687e !important; } .label { color: #f8f8f2; }',
                                    flowchart: {{{{
                                        curve: 'basis',
                                        htmlLabels: true,
                                        useMaxWidth: true
                                    }}}},
                                    graph: {{{{
                                        curve: 'basis',
                                        htmlLabels: true,
                                        useMaxWidth: true
                                    }}}},
                                    sequence: {{{{
                                        useMaxWidth: true,
                                        diagramMarginX: 50,
                                        diagramMarginY: 10,
                                        boxMargin: 10,
                                        mirrorActors: false,
                                        actorFontFamily: 'Roboto, sans-serif',
                                        noteFontFamily: 'Roboto, sans-serif',
                                        messageFontFamily: 'Roboto, sans-serif'
                                    }}}},
                                    gantt: {{{{
                                        useMaxWidth: true,
                                        fontFamily: 'Roboto, sans-serif'
                                    }}}}
                                }});
                            </script>
                            <style>
                                /* MkDocs Material theme-inspired styling */
                                :root {{
                                    --md-primary-fg-color: #526cfe;  
                                    --md-primary-fg-color--light: #8e9ffe;
                                    --md-primary-fg-color--dark: #2a3eb1;
                                    --md-accent-fg-color: #526cfe;
                                    --md-text-color: #f8f8f2;
                                    --md-code-bg-color: #272935;
                                    --md-code-fg-color: #f8f8f2;
                                }}
                                
                                body {{{{ 
                                    font-family: Roboto, "Helvetica Neue", Helvetica, Arial, sans-serif; 
                                    margin: 0; 
                                    padding: 0; 
                                    background-color: #2d3143;
                                    color: var(--md-text-color);
                                }}
                                
                                .md-container {{ 
                                    max-width: 100%;
                                    padding: 1.2rem;
                                    margin: 0 auto;
                                    background-color: #1e2029;
                                    border-radius: 0.1rem;
                                    box-shadow: 0 4px 10px rgba(0,0,0,0.2);
                                }}
                                
                                .md-header {{ 
                                    color: #ffffff; 
                                    font-size: 1.25rem;
                                    font-weight: 400;
                                    margin-bottom: 1rem;
                                    padding-bottom: 0.5rem;
                                    border-bottom: 1px solid #3f445e;
                                }}
                                
                                .md-main {{
                                    padding: 0.8rem 0;
                                }}
                                
                                .md-typeset {{
                                    font-size: 0.8rem;
                                    line-height: 1.6;
                                }}
                                
                                .md-typeset h1 {{
                                    color: var(--md-text-color);
                                    font-weight: 300;
                                    margin: 0 0 1.25rem;
                                }}
                                
                                .md-typeset .admonition {{
                                    font-size: 0.8rem;
                                    margin: 1.5625em 0;
                                    padding: 0 0.6rem;
                                    border-left: 0.2rem solid var(--md-primary-fg-color);
                                    border-radius: 0.1rem;
                                }}
                                
                                .md-typeset .admonition-title {{
                                    font-weight: 500;
                                    margin: 0 -0.6rem;
                                    padding: 0.4rem 0.6rem 0.4rem 2rem;
                                    background-color: rgba(82, 108, 254, 0.1);
                                }}
                                
                                .md-typeset code {{
                                    background-color: var(--md-code-bg-color);
                                    color: var(--md-code-fg-color);
                                    padding: 0 0.3em;
                                    border-radius: 0.1rem;
                                    font-family: "Roboto Mono", monospace;
                                }}
                                
                                .md-mermaid {{
                                    width: 100%;
                                    min-height: 400px;
                                    display: flex;
                                    justify-content: center;
                                    align-items: center;
                                    padding: 1rem 0;
                                    background-color: #272935;
                                    border-radius: 0.1rem;
                                }}
                                
                                .md-mermaid svg {{
                                    max-width: 100%;
                                    height: auto !important;
                                }}
                                
                                .md-footer {{
                                    margin-top: 1rem;
                                    padding-top: 0.5rem;
                                    border-top: 1px solid #3f445e;
                                    font-size: 0.7rem;
                                    color: #8e9ab4;
                                    text-align: center;
                                }}
                                
                                .md-footer a {{
                                    color: var(--md-primary-fg-color--light);
                                    text-decoration: none;
                                }}
                                
                                .md-footer a:hover {{
                                    text-decoration: underline;
                                }}
                                
                                .error-message {{{{
                                    color: #ff7b7b;
                                    background-color: rgba(255, 82, 82, 0.1);
                                    border: 1px solid rgba(255, 82, 82, 0.2);
                                    border-radius: 0.1rem;
                                    padding: 0.8rem;
                                    margin: 1rem 0;
                                    text-align: center;
                                }}
                                
                                /* MkDocs-specific mermaid overrides */
                                .mermaid {{
                                    background-color: #272935;
                                    border-radius: 0.1rem;
                                    padding: 1rem;
                                }}
                                
                                .mermaid .label {{{{ 
                                    font-family: Roboto, sans-serif !important;
                                    color: #f8f8f2 !important;
                                }}
                                
                                .mermaid .node rect, .mermaid .node circle, .mermaid .node ellipse, .mermaid .node polygon {{
                                    fill: #2d3143 !important;
                                    stroke: #58687e !important;
                                    stroke-width: 1px !important;
                                }}
                                
                                .mermaid .edgePath .path {{{{
                                    stroke: #58687e !important;
                                    stroke-width: 1.5px !important;
                                }}
                                
                                .mermaid .edgeLabel {{
                                    background-color: #272935 !important;
                                    color: #f8f8f2 !important;
                                }}
                                
                                .mermaid .cluster rect {{
                                    fill: #2d3143 !important;
                                    stroke: #58687e !important;
                                    stroke-width: 1px !important;
                                }}
                                
                                .mermaid .actor {{
                                    fill: #2d3143 !important;
                                    stroke: #58687e !important;
                                }}
                                
                                .mermaid text.actor {{
                                    fill: #f8f8f2 !important;
                                }}
                            </style>
                        </head>
                        <body>
                            <div class="md-container">
                                <div class="md-header">Conceptual Diagram of Chat History</div>
                                <div class="md-main">
                                    <div class="md-typeset">
                                        <div class="md-mermaid">
                                            <div class="mermaid">
{clean_mermaid_code}
                                            </div>
                                        </div>
                                        {mermaid_pre_init}
                                    </div>
                                </div>
                                <div class="md-footer">
                                    Rendered with <a href="https://github.com/fralau/mkdocs-mermaid2-plugin" target="_blank">mkdocs-mermaid2</a>
                                </div>
                            </div>
                            
                            <script>
                                // Add error handling for Mermaid rendering
                                window.addEventListener('error', function(e) {{
                                    if (e.message && e.message.includes('mermaid')) {{
                                        console.error('Mermaid error:', e);
                                        document.querySelector('.md-mermaid').innerHTML += 
                                            '<div class="error-message">Error rendering the diagram. The syntax may be invalid.</div>';
                                    }}}}
                                }});
                                
                                // Add mkdocs-specific rendering behavior
                                document.addEventListener('DOMContentLoaded', function() {{
                                    // Initialize mermaid with mkdocs-specific settings
                                    setTimeout(function() {{
                                        try {{{{
                                            console.log('Initializing mermaid diagram...');
                                            mermaid.init(undefined, document.querySelectorAll('.mermaid'));
                                            console.log('Mermaid initialization complete');
                                        }}}} catch (e) {{{{
                                            console.error('Mermaid initialization error:', e);
                                            document.querySelector('.md-mermaid').innerHTML += 
                                                '<div class="error-message">Error initializing the diagram renderer: ' + e.message + '</div>';
                                            document.getElementById('mermaid-error').style.display = 'block';
                                            document.getElementById('mermaid-error').textContent = 'Error initializing diagram: ' + e.message;
                                        }}}}
                                    }}}}, 300);
                                    
                                    // Add observer for theme changes (simulating mkdocs behavior)
                                    const observer = new MutationObserver(function() {{
                                        try {{{{
                                            // Re-render diagrams when theme changes
                                            mermaid.init(undefined, document.querySelectorAll('.mermaid'));
                                        }} catch (e) {{{{{{
                                            console.error('Mermaid re-initialization error:', e);
                                        }}}}
                                    }}}}}});
                                    
                                    // Observe document for theme changes
                                    observer.observe(document.documentElement, {{
                                        attributes: true,
                                        attributeFilter: ['data-md-color-scheme']
                                    }}}}}});
                                }});
                            </script>
                        </body>
                        </html>
                        '''
                    
                    elif renderer == "PyMdown Extension":
                        # Actual PyMdown Extension style rendering
                        # This simulates how PyMdown Extensions would render the diagram
                        # with the Material for MkDocs styling that PyMdown typically uses
                        
                        # Create a PyMdown-style container for the mermaid diagram
                        # Use the same mermaid_div approach as the default renderer for consistency
                        html_content = f'''
                        <!DOCTYPE html>
                        <html>
                        <head>
                            <script src="https://cdn.jsdelivr.net/npm/mermaid@9.1.7/dist/mermaid.min.js"></script>
                            <link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:wght@400;700&family=Source+Sans+Pro:wght@300;400;600&display=swap" rel="stylesheet">
                            <script>
                                // Configuration specific to PyMdown Extensions
                                mermaid.initialize({{{{
                                    startOnLoad: false,  // We'll manually initialize for better control
                                    theme: 'neutral',
                                    logLevel: 'error',
                                    securityLevel: 'loose',
                                    fontFamily: '"Source Sans Pro", "Helvetica Neue", Helvetica, Arial, sans-serif',
                                    fontSize: 14,
                                    flowchart: {{{{
                                        curve: 'linear',
                                        htmlLabels: true,
                                        useMaxWidth: true,
                                        diagramPadding: 8
                                    }}}},
                                    sequence: {{{{
                                        useMaxWidth: true,
                                        diagramMarginX: 50,
                                        diagramMarginY: 10,
                                        boxMargin: 10,
                                        mirrorActors: false,
                                        actorFontFamily: '"Source Sans Pro", sans-serif',
                                        noteFontFamily: '"Source Sans Pro", sans-serif',
                                        messageFontFamily: '"Source Sans Pro", sans-serif'
                                    }}}},
                                    gantt: {{{{
                                        useMaxWidth: true,
                                        fontFamily: '"Source Sans Pro", sans-serif'
                                    }}}}
                                }});
                            </script>
                            <style>
                                /* PyMdown Extensions with Material theme styling */
                                :root {{
                                    --md-primary-fg-color: #3f51b5;  
                                    --md-primary-fg-color--light: #7986cb;
                                    --md-primary-fg-color--dark: #303f9f;
                                    --md-accent-fg-color: #ff4081;
                                    --md-text-color: #212121;
                                    --md-code-bg-color: #f5f5f5;
                                    --md-code-fg-color: #37474f;
                                    --md-footer-bg-color: #424242;
                                    --md-footer-fg-color: #f5f5f5;
                                }}
                                
                                body {{{{ 
                                    font-family: "Source Sans Pro", "Helvetica Neue", Helvetica, Arial, sans-serif; 
                                    margin: 0; 
                                    padding: 0; 
                                    background-color: #fafafa;
                                    color: var(--md-text-color);
                                    line-height: 1.6;
                                }}
                                
                                .pymdown-container {{ 
                                    max-width: 100%;
                                    padding: 1.2rem;
                                    margin: 0 auto;
                                    background-color: #ffffff;
                                    border-radius: 0.2rem;
                                    box-shadow: 0 1px 3px rgba(0,0,0,0.12), 0 1px 2px rgba(0,0,0,0.24);
                                }}
                                
                                .pymdown-header {{ 
                                    color: var(--md-primary-fg-color); 
                                    font-size: 1.25rem;
                                    font-weight: 400;
                                    margin-bottom: 1rem;
                                    padding-bottom: 0.5rem;
                                    border-bottom: 1px solid rgba(0,0,0,0.07);
                                }}
                                
                                .pymdown-content {{
                                    padding: 0.8rem 0;
                                }}
                                
                                .pymdown-mermaid {{
                                    width: 100%;
                                    min-height: 400px;
                                    display: flex;
                                    justify-content: center;
                                    align-items: center;
                                    padding: 1rem 0;
                                    background-color: #ffffff;
                                    border: 1px solid rgba(0,0,0,0.07);
                                    border-radius: 0.2rem;
                                }}
                                
                                .pymdown-mermaid svg {{
                                    max-width: 100%;
                                    height: auto !important;
                                }}
                                
                                .pymdown-footer {{
                                    margin-top: 1rem;
                                    padding-top: 0.5rem;
                                    border-top: 1px solid rgba(0,0,0,0.07);
                                    font-size: 0.7rem;
                                    color: rgba(0,0,0,0.54);
                                    text-align: center;
                                }}
                                
                                .pymdown-footer a {{
                                    color: var(--md-primary-fg-color);
                                    text-decoration: none;
                                }}
                                
                                .pymdown-footer a:hover {{
                                    text-decoration: underline;
                                }}
                                
                                .error-message {{{{
                                    color: #f44336;
                                    background-color: #ffebee;
                                    border: 1px solid #ffcdd2;
                                    border-radius: 0.2rem;
                                    padding: 0.8rem;
                                    margin: 1rem 0;
                                    text-align: center;
                                }}
                                
                                /* Material theme code block styling */
                                .md-typeset code {{
                                    background-color: var(--md-code-bg-color);
                                    color: var(--md-code-fg-color);
                                    padding: 0 0.3em;
                                    border-radius: 0.2rem;
                                    font-family: "Roboto Mono", monospace;
                                    font-size: 0.85em;
                                }}
                                
                                .md-typeset pre {{
                                    background-color: var(--md-code-bg-color);
                                    color: var(--md-code-fg-color);
                                    line-height: 1.4;
                                    border-radius: 0.2rem;
                                    padding: 0.8rem;
                                    margin: 1rem 0;
                                    overflow: auto;
                                }}
                                
                                /* PyMdown-specific mermaid overrides */
                                .mermaid {{
                                    font-family: "Source Sans Pro", sans-serif;
                                }}
                                
                                .mermaid .label {{{{ 
                                    font-family: "Source Sans Pro", sans-serif !important;
                                    color: #212121 !important;
                                    font-size: 14px !important;
                                }}
                                
                                .mermaid .node rect, .mermaid .node circle, .mermaid .node ellipse, .mermaid .node polygon {{
                                    fill: #e3f2fd !important;
                                    stroke: #90caf9 !important;
                                    stroke-width: 1px !important;
                                }}
                                
                                .mermaid .edgePath .path {{{{
                                    stroke: #2196f3 !important;
                                    stroke-width: 1.5px !important;
                                }}
                                
                                .mermaid .edgeLabel {{
                                    background-color: #ffffff !important;
                                    color: #212121 !important;
                                }}
                                
                                .mermaid .cluster rect {{
                                    fill: #e8eaf6 !important;
                                    stroke: #c5cae9 !important;
                                    stroke-width: 1px !important;
                                }}
                                
                                .mermaid .actor {{
                                    fill: #e3f2fd !important;
                                    stroke: #90caf9 !important;
                                }}
                                
                                .mermaid text.actor {{
                                    fill: #212121 !important;
                                }}
                                
                                /* Admonition styling (typical in PyMdown) */
                                .admonition {{
                                    margin: 1.5625em 0;
                                    padding: 0 0.6rem;
                                    overflow: hidden;
                                    font-size: 0.8rem;
                                    border-left: 0.2rem solid #448aff;
                                    border-radius: 0.1rem;
                                    background-color: rgba(68, 138, 255, 0.1);
                                }}
                                
                                .admonition-title {{
                                    margin: 0 -0.6rem;
                                    padding: 0.4rem 0.6rem 0.4rem 2rem;
                                    font-weight: 700;
                                    background-color: rgba(68, 138, 255, 0.1);
                                }}
                            </style>
                        </head>
                        <body>
                            <div class="pymdown-container">
                                <div class="pymdown-header">Conceptual Diagram of Chat History</div>
                                <div class="pymdown-content">
                                    <div class="pymdown-mermaid">
                                        <pre class="mermaid">
{clean_mermaid_code}
                                        </pre>
                                    </div>
                                    {mermaid_pre_init}
                                    
                                    <!-- Example of PyMdown-style admonition (for demonstration) -->
                                    <div class="admonition note">
                                        <p class="admonition-title">Note</p>
                                        <p>This diagram is rendered using the PyMdown Extensions style, which is commonly used with Material for MkDocs.</p>
                                    </div>
                                </div>
                                <div class="pymdown-footer">
                                    Rendered with <a href="https://facelessuser.github.io/pymdown-extensions/extensions/superfences/#uml-diagram-example" target="_blank">PyMdown Extensions</a> style
                                </div>
                            </div>
                            
                            <script>
                                // Add error handling for Mermaid rendering
                                window.addEventListener('error', function(e) {{
                                    if (e.message && e.message.includes('mermaid')) {{
                                        console.error('Mermaid error:', e);
                                        document.querySelector('.pymdown-mermaid').innerHTML += 
                                            '<div class="error-message">Error rendering the diagram. The syntax may be invalid.</div>';
                                    }}}}
                                }});
                                
                                // Add PyMdown-specific rendering behavior
                                document.addEventListener('DOMContentLoaded', function() {{
                                    // Initialize mermaid with PyMdown-specific settings
                                    try {{{{
                                        if (typeof mermaid !== 'undefined') {{
                                            mermaid.init(undefined, document.querySelectorAll('.mermaid'));
                                        }}}}
                                    }} catch (e) {{{{{{
                                        console.error('Mermaid initialization error:', e);
                                        document.querySelector('.pymdown-mermaid').innerHTML += 
                                            '<div class="error-message">Error initializing the diagram renderer.</div>';
                                    }}}}
                                    
                                    // Add support for clicking on diagram elements (common in PyMdown)
                                    document.querySelectorAll('.mermaid svg a').forEach(function(link) {{
                                        link.addEventListener('click', function(e) {{
                                            e.preventDefault();
                                            const href = this.getAttribute('xlink:href');
                                            if (href && !href.startsWith('#')) {{
                                                window.open(href, '_blank');
                                            }}}}
                                        }}}}}});
                                    }}}})});
                                }});
                            </script>
                        </body>
                        </html>
                        '''
                    
                    # Use iframe to render the HTML content
                    # Escape single quotes in the HTML content
                    html_content_escaped = html_content.replace("'", "&#39;")
                    # Use string format instead of f-string for better reliability
                    iframe_template = '<iframe srcdoc="{}" width="100%" height="600" style="border:none;"></iframe>'
                    iframe_html = iframe_template.format(html_content_escaped.replace('"', '&quot;'))
                    
                    diagram_status.value = "Conceptual diagram generated successfully!"
                    return iframe_html, "Conceptual diagram generated successfully!"
                
                except Exception as e:
                    import traceback
                    error_details = traceback.format_exc()
                    print(f"Error generating conceptual diagram: {str(e)}\n{error_details}")
                    diagram_status.value = f"Error generating diagram: {str(e)}"
                    return None, f"Error generating diagram: {str(e)}"
            
            # Connect conceptual diagram button
            create_diagram_btn.click(
                fn=generate_chat_diagram,
                inputs=[chat_history_state, diagram_renderer],
                outputs=[diagram_output, diagram_status],
            )

        await demo.launch(
            server_name=chat_config.server_name,
            share=chat_config.share,
            inbrowser=chat_config.inbrowser
        )
    
    except Exception as e:
        logger.error(f"Application error: {str(e)}")
        raise
    finally:
        if chat_interface:
            await chat_interface.cleanup()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("Application terminated by user")
    except Exception as e:
        logger.error(f"Application failed: {str(e)}") 